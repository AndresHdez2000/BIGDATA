{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions Big Data Principles\n",
    "\n",
    "\n",
    "\n",
    "### Chapter 1\n",
    "\n",
    "1.- Mention an advantage and a disadvantage of using Hadoop as your computational sytem to handle large amounts of data. Do you think that Elasticsearch could help with the disadvantage? \n",
    "- R.- It can use large amount of data and make their process paralleized, the disadvantage is that it computes with high latancy. No because the elasticsearch engines would help in the visuzalization part, not before\n",
    "\n",
    "2.- Imaine that you have de dumbest personal in your company and they have lots of executioanl erros, which property need to be changed in order to have a human mistake tolerance. Why?\n",
    "- R. it needs to be inmutable, because if it is inmutable you are only having bar registers, otherwise they would be damaging the entire data\n",
    "\n",
    "3.- In the whole chapter 1, a concept is repeted several times, it is very important for scalability... which \"concept\" are we talking about? what would be the natural funciton of this?\n",
    "- R.- Lambda Architecture, to implement any function on any data. \n",
    "\n",
    "4.- According to the book which theorem states that a service which is availability and full consistency?, name the characteristics of the theorem.\n",
    "\n",
    "- R.-CAP- CONSISTENCY, AVAILABILIT, PARTITION TOLERANCE.  choose 2 and forget about the otherone. \n",
    "\n",
    "5.- Lets say that a business needs consistency and partition tolerance. which platform would you use? \n",
    "- R.-Mongo DB, HBase, Redis, Memcache\n",
    "\n",
    "6.- Lets say that you are working with a hospital in this COVID-19 situation, it is a small hospital, which characteristics of the theorem that we saw before would you take? \n",
    "- R.- Availability and Consistency\n",
    "\n",
    "7.- If you want a tool or system which can handle failiors at the software layer, which computaional system would you use?\n",
    "- R.- MapReduce \n",
    "\n",
    "8.- Taking in count the question number 7, would you say that this \"system\" is implemented in elasticsearch? would you say that it makes this process when ir reach Kibana, or before reaching kibana?\n",
    "- R.- It may not be the same mapping, but it is likely, and it would be before reaching Kibana. \n",
    "\n",
    "## Part 1\n",
    "\n",
    "\n",
    "### Chapter 2 \n",
    "\n",
    "1 If your boss asked you to delate some data and it is not a wide dataset, what would you do?? What would be your next step?\n",
    "- R.- Create a second copy... the second question is optional, but you shoud replace it after filtraiting. \n",
    "\n",
    "2 The book states to different \"structures\" that can be used to represantate data. Give the name of these \"structures\", and state which one are we using in the last week activities.\n",
    "- R.- XML, JSON. The structuree that we are using is a JSON format.\n",
    "\n",
    "3 What is the difference between structured and semistructured data? Can you fing another profile? Name it and tell the characteristics. \n",
    "- R.- Structured data is the one that can be addressable, it is also organized, an example could be the relational data. the semistructures are the ones such as XML and JSON, it is the data that cannot be in a database because of the lack of fields, it can be analyzed and it has keys, can be turned into structured data. the unstrutured data\n",
    "\n",
    "4 In chapter 2 they talk about graph schemas, but in chapter 1 they mention what happend with data if there is any anomalie or at introducing data. what would be a complication(mentioned)....? what process does it take in count when you input new data(according to chapter 1)? \n",
    "- R.- A bad input of a register, a timestamp for example. It does a rebalance onto the new nodes\n",
    "\n",
    "5 State the 4 principal advantages of the big data paradigm, also explain why are they advantages\n",
    "- R.- Is queryable at any time in its history, tolerates human errors, handles partial information, has the advantages of both normalized and denormalized forms. It is accecible whenever you want, the mistakes from humans are not very worring because it is inmutables so you only have to delate, it can be fill with NULL's automatically, finally, it is devided into two different sections what let you extract the best characteristics of each. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3\n",
    "\n",
    "1.- Imagine that you have 3 teams, and you ask them to send you a file with some information, one of them sends you a JSON fiel, another sends a XSON and another one an object file form a random program. What would you use as a tool to solve this problem, and why?\n",
    "- R We would use a serialization framework, this  because the serialization will take the 3 different files, and it will be measuring by the stream of bytes the information that it has. So if you have 3 different objects, after the serialization, these 3 objects will be the same with different info.\n",
    "\n",
    "\n",
    "2.- My team is facing a problem with the data, they have searched and supervised the source code, and they do not find any mistake, we have spent days searching this mistake, we are now in the downstream of the process. Can you mention these error... and would you be so kind of give me some steps to debug it?\n",
    "- R This is a Data corruption issue, there is a list of steps to avoid this... Gather data, Get the data out of the computer and into your brain via the highest bandwidth channel available, look for patterns, develop a reproducible test case, Run the reproducible test case (THIS IS NOT A UNIQUE ANSWERE)\n",
    "\n",
    "\n",
    "3.- In the book they mention a program that can help you in order to avoid problems, If you have an node gender is gender, and now in the 2020 the person does not feel confortable whith saying its gender, what is the program that would help me? is there any option that we can change in order to accept this person? which one it is? and explain yourself.\n",
    "- R The program metioned by the book is thrift, and there is an option which you can change in order to have missing values. It has 2 option for the field, optional or required, we should fix it to be optional\n",
    "\n",
    "\n",
    "4.- As long as the serialization has some limitations, give some example where this cannot work, or you would have data with good quality no matter if they are the same type. Give a solution for this problem. \n",
    "- R Fields with discrete numbers, time traveling with the time stamps. The solution would be to have a programming language able to mix the different inputs and translate it to the language that we want. ACOORDING TO THE BOOK IS POSSIBLE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 4\n",
    "\n",
    "1.- What would you implement if you wanted to read lots of data, which can be resposbale of the computing functions in a data set... which batch layer would you choose.\n",
    "- R Storage system, It needs to be able to read lots of data at the same time, the benefit of working this say is that your limitants are quite easy to understand, the limitant of these batch layer is that it is not able to check the unique/specific values of the data.\n",
    "\n",
    "2.- There is a system which allows you to store data, and match it. It is abele to have different sub settigns of the data, mixed in different cubes, just like a jig saw puzzle. cand you name this system? Give some characteriscs and advantages.\n",
    "- R Distributed Filesystem. Files are spread across multiple machines for scalability and also to enable parallel processing, file blocks are replicated across multiple nodes for fault tolerance\n",
    "\n",
    "3.-As you know there is a batch layer that is retrigted to access to specific information, like key:value infrmation, there is an option that you my want to implement with your filsystem, which may allow you to fight this disadvatage by making substetting in order, which implementaiton needs to be done? how is the implementaiton? \n",
    "- R Vertical Partitioning. The vertical partitiong will be an implementation that is going to help you to have order in your files system, because as you may remember, it subset your data all mixed, and also to have a particular infomration together, so that it is easier to access from the storage system. \n",
    "\n",
    "4.- What information would you find in a file where the vertical partitioning is implmented?\n",
    "- R I would find all the information that is in that section of the file, it is possible that the master data set could be sorted by timestamp, or by a mesurement, or critiria on the creation of these files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
